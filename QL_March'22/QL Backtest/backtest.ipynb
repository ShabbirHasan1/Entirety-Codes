{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f82a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "#Trade Logic\n",
    "#Instrument\n",
    "#TradeLog\n",
    "\n",
    "#Metrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647ea22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e0ee1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = pd.DataFrame(glob('/Users/yashraj/Documents/QL/QL Data/banknifty/*'),columns=['location'])\n",
    "all_files['data_date'] = pd.to_datetime(all_files['location'].apply(lambda x: re.findall(r'[0-9]{4}-[0-9]{2}-[0-9]{2}',x)[0]))\n",
    "all_files.sort_values('data_date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f041ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcefd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_type = 'short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c6fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_offset = 'close'\n",
    "\n",
    "if system_type == 'short':\n",
    "    stop_loss_offset = 'high'\n",
    "elif system_type == 'long':\n",
    "    stop_loss_offset = 'low'\n",
    "\n",
    "weekday_dict = {0:'MONDAY',\n",
    "                1:'TUESDAY',\n",
    "                2:'WEDNESDAY',\n",
    "                3:'THURSDAY',\n",
    "                4:'FRIDAY',\n",
    "                5:'SATURDAY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dae75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_time = datetime.time(9,20)\n",
    "exit_time = datetime.time(15,14)\n",
    "stop_loss_percentage = 0.40\n",
    "instrument = 'BANKNIFTY'\n",
    "base = 100\n",
    "option_value = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe799b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FETCHED DATA FOR 2021-01-01\n",
      "FETCHED DATA FOR 2021-01-04\n",
      "FETCHED DATA FOR 2021-01-05\n",
      "FETCHED DATA FOR 2021-01-06\n",
      "FETCHED DATA FOR 2021-01-07\n",
      "FETCHED DATA FOR 2021-01-08\n",
      "FETCHED DATA FOR 2021-01-11\n",
      "FETCHED DATA FOR 2021-01-12\n",
      "FETCHED DATA FOR 2021-01-13\n",
      "FETCHED DATA FOR 2021-01-14\n",
      "FETCHED DATA FOR 2021-01-15\n",
      "FETCHED DATA FOR 2021-01-18\n",
      "FETCHED DATA FOR 2021-01-19\n",
      "FETCHED DATA FOR 2021-01-20\n",
      "FETCHED DATA FOR 2021-01-21\n",
      "FETCHED DATA FOR 2021-01-22\n",
      "FETCHED DATA FOR 2021-01-25\n",
      "FETCHED DATA FOR 2021-01-27\n",
      "FETCHED DATA FOR 2021-01-28\n",
      "FETCHED DATA FOR 2021-01-29\n",
      "FETCHED DATA FOR 2021-02-01\n",
      "FETCHED DATA FOR 2021-02-02\n",
      "FETCHED DATA FOR 2021-02-03\n",
      "FETCHED DATA FOR 2021-02-04\n",
      "FETCHED DATA FOR 2021-02-05\n",
      "FETCHED DATA FOR 2021-02-08\n",
      "FETCHED DATA FOR 2021-02-09\n",
      "FETCHED DATA FOR 2021-02-10\n",
      "FETCHED DATA FOR 2021-02-11\n",
      "FETCHED DATA FOR 2021-02-12\n",
      "FETCHED DATA FOR 2021-02-15\n",
      "FETCHED DATA FOR 2021-02-16\n",
      "FETCHED DATA FOR 2021-02-17\n",
      "FETCHED DATA FOR 2021-02-18\n",
      "FETCHED DATA FOR 2021-02-19\n",
      "FETCHED DATA FOR 2021-02-22\n",
      "FETCHED DATA FOR 2021-02-23\n",
      "FETCHED DATA FOR 2021-02-24\n",
      "ERROR ON DATE 2021-02-24\n",
      "FETCHED DATA FOR 2021-02-25\n",
      "FETCHED DATA FOR 2021-02-26\n",
      "FETCHED DATA FOR 2021-03-01\n",
      "FETCHED DATA FOR 2021-03-02\n",
      "FETCHED DATA FOR 2021-03-03\n",
      "FETCHED DATA FOR 2021-03-04\n",
      "FETCHED DATA FOR 2021-03-05\n",
      "FETCHED DATA FOR 2021-03-08\n",
      "FETCHED DATA FOR 2021-03-09\n",
      "FETCHED DATA FOR 2021-03-10\n",
      "FETCHED DATA FOR 2021-03-12\n",
      "ATM ERROR 2021-03-12\n",
      "FETCHED DATA FOR 2021-03-15\n",
      "FETCHED DATA FOR 2021-03-16\n",
      "FETCHED DATA FOR 2021-03-17\n",
      "FETCHED DATA FOR 2021-03-18\n",
      "FETCHED DATA FOR 2021-03-19\n",
      "FETCHED DATA FOR 2021-03-22\n",
      "FETCHED DATA FOR 2021-03-23\n",
      "FETCHED DATA FOR 2021-03-24\n",
      "FETCHED DATA FOR 2021-03-25\n",
      "FETCHED DATA FOR 2021-03-26\n",
      "FETCHED DATA FOR 2021-03-30\n",
      "FETCHED DATA FOR 2021-03-31\n",
      "FETCHED DATA FOR 2021-04-01\n",
      "FETCHED DATA FOR 2021-04-05\n",
      "FETCHED DATA FOR 2021-04-06\n",
      "FETCHED DATA FOR 2021-04-07\n",
      "FETCHED DATA FOR 2021-04-08\n",
      "FETCHED DATA FOR 2021-04-09\n",
      "FETCHED DATA FOR 2021-04-12\n",
      "FETCHED DATA FOR 2021-04-13\n",
      "FETCHED DATA FOR 2021-04-15\n",
      "FETCHED DATA FOR 2021-04-16\n",
      "FETCHED DATA FOR 2021-04-19\n",
      "FETCHED DATA FOR 2021-04-20\n",
      "FETCHED DATA FOR 2021-04-22\n",
      "FETCHED DATA FOR 2021-04-23\n",
      "FETCHED DATA FOR 2021-04-26\n",
      "FETCHED DATA FOR 2021-04-27\n",
      "FETCHED DATA FOR 2021-04-28\n",
      "FETCHED DATA FOR 2021-04-29\n",
      "FETCHED DATA FOR 2021-04-30\n",
      "FETCHED DATA FOR 2021-05-03\n",
      "FETCHED DATA FOR 2021-05-04\n",
      "FETCHED DATA FOR 2021-05-05\n",
      "FETCHED DATA FOR 2021-05-06\n",
      "FETCHED DATA FOR 2021-05-07\n",
      "FETCHED DATA FOR 2021-05-10\n",
      "FETCHED DATA FOR 2021-05-11\n",
      "FETCHED DATA FOR 2021-05-12\n",
      "FETCHED DATA FOR 2021-05-14\n",
      "FETCHED DATA FOR 2021-05-17\n",
      "FETCHED DATA FOR 2021-05-18\n",
      "FETCHED DATA FOR 2021-05-19\n",
      "FETCHED DATA FOR 2021-05-20\n",
      "FETCHED DATA FOR 2021-05-21\n",
      "FETCHED DATA FOR 2021-05-24\n",
      "FETCHED DATA FOR 2021-05-25\n",
      "FETCHED DATA FOR 2021-05-26\n",
      "FETCHED DATA FOR 2021-05-27\n",
      "FETCHED DATA FOR 2021-05-28\n",
      "FETCHED DATA FOR 2021-06-01\n",
      "FETCHED DATA FOR 2021-06-02\n",
      "FETCHED DATA FOR 2021-06-03\n",
      "FETCHED DATA FOR 2021-06-04\n",
      "FETCHED DATA FOR 2021-06-07\n",
      "FETCHED DATA FOR 2021-06-08\n",
      "FETCHED DATA FOR 2021-06-09\n",
      "FETCHED DATA FOR 2021-06-10\n",
      "FETCHED DATA FOR 2021-06-11\n",
      "FETCHED DATA FOR 2021-06-14\n",
      "FETCHED DATA FOR 2021-06-15\n",
      "FETCHED DATA FOR 2021-06-16\n",
      "FETCHED DATA FOR 2021-06-17\n",
      "FETCHED DATA FOR 2021-06-18\n",
      "FETCHED DATA FOR 2021-06-21\n",
      "FETCHED DATA FOR 2021-06-22\n",
      "FETCHED DATA FOR 2021-06-23\n",
      "FETCHED DATA FOR 2021-06-24\n",
      "FETCHED DATA FOR 2021-06-25\n",
      "FETCHED DATA FOR 2021-06-28\n",
      "FETCHED DATA FOR 2021-06-29\n",
      "FETCHED DATA FOR 2021-06-30\n",
      "FETCHED DATA FOR 2021-07-01\n",
      "FETCHED DATA FOR 2021-07-02\n",
      "FETCHED DATA FOR 2021-07-05\n",
      "FETCHED DATA FOR 2021-07-06\n",
      "FETCHED DATA FOR 2021-07-07\n",
      "FETCHED DATA FOR 2021-07-08\n",
      "FETCHED DATA FOR 2021-07-09\n",
      "FETCHED DATA FOR 2021-07-12\n",
      "FETCHED DATA FOR 2021-07-13\n",
      "FETCHED DATA FOR 2021-07-14\n",
      "FETCHED DATA FOR 2021-07-15\n",
      "FETCHED DATA FOR 2021-07-16\n",
      "FETCHED DATA FOR 2021-07-19\n",
      "FETCHED DATA FOR 2021-07-20\n",
      "FETCHED DATA FOR 2021-07-22\n",
      "FETCHED DATA FOR 2021-07-23\n",
      "FETCHED DATA FOR 2021-07-26\n",
      "FETCHED DATA FOR 2021-07-27\n",
      "FETCHED DATA FOR 2021-07-28\n",
      "FETCHED DATA FOR 2021-07-29\n",
      "FETCHED DATA FOR 2021-07-30\n",
      "FETCHED DATA FOR 2021-08-02\n",
      "FETCHED DATA FOR 2021-08-03\n",
      "FETCHED DATA FOR 2021-08-04\n",
      "FETCHED DATA FOR 2021-08-05\n",
      "FETCHED DATA FOR 2021-08-06\n",
      "FETCHED DATA FOR 2021-08-09\n",
      "FETCHED DATA FOR 2021-08-10\n",
      "FETCHED DATA FOR 2021-08-11\n",
      "FETCHED DATA FOR 2021-08-12\n",
      "FETCHED DATA FOR 2021-08-13\n",
      "FETCHED DATA FOR 2021-08-16\n",
      "FETCHED DATA FOR 2021-08-17\n",
      "FETCHED DATA FOR 2021-08-18\n",
      "FETCHED DATA FOR 2021-08-20\n",
      "FETCHED DATA FOR 2021-08-23\n",
      "FETCHED DATA FOR 2021-08-24\n",
      "FETCHED DATA FOR 2021-08-25\n",
      "FETCHED DATA FOR 2021-08-26\n",
      "FETCHED DATA FOR 2021-08-27\n",
      "FETCHED DATA FOR 2021-08-30\n",
      "FETCHED DATA FOR 2021-08-31\n",
      "FETCHED DATA FOR 2021-09-01\n",
      "FETCHED DATA FOR 2021-09-02\n",
      "FETCHED DATA FOR 2021-09-03\n",
      "FETCHED DATA FOR 2021-09-07\n",
      "FETCHED DATA FOR 2021-09-08\n",
      "FETCHED DATA FOR 2021-09-09\n",
      "FETCHED DATA FOR 2021-09-13\n",
      "FETCHED DATA FOR 2021-09-14\n",
      "FETCHED DATA FOR 2021-09-15\n",
      "FETCHED DATA FOR 2021-09-16\n",
      "FETCHED DATA FOR 2021-09-17\n",
      "FETCHED DATA FOR 2021-09-20\n",
      "FETCHED DATA FOR 2021-09-21\n",
      "FETCHED DATA FOR 2021-09-22\n",
      "FETCHED DATA FOR 2021-09-23\n",
      "FETCHED DATA FOR 2021-09-24\n",
      "FETCHED DATA FOR 2021-09-27\n",
      "FETCHED DATA FOR 2021-09-28\n",
      "FETCHED DATA FOR 2021-09-29\n",
      "FETCHED DATA FOR 2021-09-30\n",
      "FETCHED DATA FOR 2021-10-01\n",
      "FETCHED DATA FOR 2021-10-04\n",
      "FETCHED DATA FOR 2021-10-05\n",
      "FETCHED DATA FOR 2021-10-06\n",
      "FETCHED DATA FOR 2021-10-07\n",
      "FETCHED DATA FOR 2021-10-08\n",
      "FETCHED DATA FOR 2021-10-11\n",
      "FETCHED DATA FOR 2021-10-12\n",
      "FETCHED DATA FOR 2021-10-13\n",
      "FETCHED DATA FOR 2021-10-14\n",
      "FETCHED DATA FOR 2021-10-18\n",
      "FETCHED DATA FOR 2021-10-19\n",
      "FETCHED DATA FOR 2021-10-20\n",
      "FETCHED DATA FOR 2021-10-21\n",
      "FETCHED DATA FOR 2021-10-22\n",
      "FETCHED DATA FOR 2021-10-25\n",
      "FETCHED DATA FOR 2021-10-26\n",
      "FETCHED DATA FOR 2021-10-27\n",
      "FETCHED DATA FOR 2021-10-28\n",
      "FETCHED DATA FOR 2021-10-29\n",
      "FETCHED DATA FOR 2021-11-01\n",
      "FETCHED DATA FOR 2021-11-02\n",
      "FETCHED DATA FOR 2021-11-03\n",
      "FETCHED DATA FOR 2021-11-04\n",
      "ATM ERROR 2021-11-04\n",
      "FETCHED DATA FOR 2021-11-08\n",
      "FETCHED DATA FOR 2021-11-09\n",
      "FETCHED DATA FOR 2021-11-10\n",
      "FETCHED DATA FOR 2021-11-11\n",
      "FETCHED DATA FOR 2021-11-12\n",
      "FETCHED DATA FOR 2021-11-15\n",
      "FETCHED DATA FOR 2021-11-16\n",
      "FETCHED DATA FOR 2021-11-17\n",
      "FETCHED DATA FOR 2021-11-18\n",
      "FETCHED DATA FOR 2021-11-22\n",
      "FETCHED DATA FOR 2021-11-23\n",
      "FETCHED DATA FOR 2021-11-24\n",
      "FETCHED DATA FOR 2021-11-25\n",
      "FETCHED DATA FOR 2021-11-26\n",
      "FETCHED DATA FOR 2021-11-29\n",
      "FETCHED DATA FOR 2021-11-30\n",
      "FETCHED DATA FOR 2021-12-01\n",
      "FETCHED DATA FOR 2021-12-02\n",
      "FETCHED DATA FOR 2021-12-03\n",
      "FETCHED DATA FOR 2021-12-06\n",
      "FETCHED DATA FOR 2021-12-07\n",
      "FETCHED DATA FOR 2021-12-08\n",
      "FETCHED DATA FOR 2021-12-09\n",
      "FETCHED DATA FOR 2021-12-10\n",
      "FETCHED DATA FOR 2021-12-13\n",
      "FETCHED DATA FOR 2021-12-14\n",
      "FETCHED DATA FOR 2021-12-15\n",
      "FETCHED DATA FOR 2021-12-16\n",
      "FETCHED DATA FOR 2021-12-17\n",
      "FETCHED DATA FOR 2021-12-20\n",
      "FETCHED DATA FOR 2021-12-21\n",
      "FETCHED DATA FOR 2021-12-22\n",
      "FETCHED DATA FOR 2021-12-23\n",
      "FETCHED DATA FOR 2021-12-24\n",
      "FETCHED DATA FOR 2021-12-27\n",
      "FETCHED DATA FOR 2021-12-28\n",
      "FETCHED DATA FOR 2021-12-29\n",
      "FETCHED DATA FOR 2021-12-30\n",
      "FETCHED DATA FOR 2021-12-31\n",
      "FETCHED DATA FOR 2022-01-03\n",
      "FETCHED DATA FOR 2022-01-04\n",
      "FETCHED DATA FOR 2022-01-05\n",
      "FETCHED DATA FOR 2022-01-06\n",
      "FETCHED DATA FOR 2022-01-07\n",
      "FETCHED DATA FOR 2022-01-10\n",
      "FETCHED DATA FOR 2022-01-11\n",
      "FETCHED DATA FOR 2022-01-12\n",
      "FETCHED DATA FOR 2022-01-13\n",
      "FETCHED DATA FOR 2022-01-14\n",
      "FETCHED DATA FOR 2022-01-17\n",
      "FETCHED DATA FOR 2022-01-18\n",
      "FETCHED DATA FOR 2022-01-19\n",
      "FETCHED DATA FOR 2022-01-20\n",
      "FETCHED DATA FOR 2022-01-21\n",
      "FETCHED DATA FOR 2022-01-24\n",
      "FETCHED DATA FOR 2022-01-25\n",
      "FETCHED DATA FOR 2022-01-27\n",
      "FETCHED DATA FOR 2022-01-28\n",
      "FETCHED DATA FOR 2022-01-31\n",
      "FETCHED DATA FOR 2022-02-01\n",
      "FETCHED DATA FOR 2022-02-02\n",
      "FETCHED DATA FOR 2022-02-03\n",
      "FETCHED DATA FOR 2022-02-04\n",
      "FETCHED DATA FOR 2022-02-07\n",
      "FETCHED DATA FOR 2022-02-08\n",
      "FETCHED DATA FOR 2022-02-09\n",
      "FETCHED DATA FOR 2022-02-10\n",
      "FETCHED DATA FOR 2022-02-11\n",
      "FETCHED DATA FOR 2022-02-14\n",
      "FETCHED DATA FOR 2022-02-15\n",
      "FETCHED DATA FOR 2022-02-16\n",
      "FETCHED DATA FOR 2022-02-17\n",
      "FETCHED DATA FOR 2022-02-18\n",
      "FETCHED DATA FOR 2022-02-21\n",
      "FETCHED DATA FOR 2022-02-22\n",
      "FETCHED DATA FOR 2022-02-23\n",
      "FETCHED DATA FOR 2022-02-24\n",
      "FETCHED DATA FOR 2022-02-25\n",
      "FETCHED DATA FOR 2022-02-28\n",
      "FETCHED DATA FOR 2022-03-02\n",
      "FETCHED DATA FOR 2022-03-03\n",
      "FETCHED DATA FOR 2022-03-04\n",
      "FETCHED DATA FOR 2022-03-07\n",
      "FETCHED DATA FOR 2022-03-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FETCHED DATA FOR 2022-03-09\n"
     ]
    }
   ],
   "source": [
    "trade_log = pd.DataFrame(columns=['entry_date','days_to_expiry','stop_loss','ce_entry_time','ce_symbol','ce_entry','ce_exit','ce_exit_time','ce_pnl','pe_entry_time','pe_symbol','pe_entry','pe_exit','pe_exit_time','pe_pnl'])\n",
    "\n",
    "for index, row in all_files[495:].iterrows():\n",
    "\n",
    "    data = pd.read_parquet(row['location'])\n",
    "    data.sort_values('datetime',inplace=True)\n",
    "    data_date = row['data_date'].date()\n",
    "    data['strike_price'] = data['strike_price'].apply(float)\n",
    "    \n",
    "    print(f'FETCHED DATA FOR {data_date}')\n",
    "\n",
    "    ce_strike_alternatives = 0\n",
    "    pe_strike_alternatives = 0\n",
    "    entry_minutes_alternative = 1\n",
    "\n",
    "    entry_datetime = datetime.datetime.combine(data_date,entry_time)\n",
    "    exit_datetime = datetime.datetime.combine(data_date,exit_time)\n",
    "\n",
    "    #futures_nearest_expiry = data[(data['instrument_type'] == 'FUT') & (data['expiry_date'] >= data_date)]['expiry_date'].min()\n",
    "        \n",
    "    #subset the futures data\n",
    "    futures_data = data[(data['instrument_type'] == 'FUT') & (data['expiry_type'] == 'I')].copy()\n",
    "    futures_data.drop_duplicates(subset=['datetime'],keep='first',inplace=True)\n",
    "    futures_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    futures_data.sort_values(by='datetime',inplace=True)\n",
    "\n",
    "    try:\n",
    "        atm = base*np.round(futures_data[futures_data['datetime'] == entry_datetime]['open'].iloc[0]/base)\n",
    "    except IndexError:\n",
    "        print(f'ATM ERROR {data_date}')\n",
    "        continue\n",
    "\n",
    "    #get the nearest option expiry\n",
    "    nearest_expiry = data[((data['instrument_type'] == 'CE')|(data['instrument_type'] == 'PE')) & (data['expiry_date'] >= data_date)]['expiry_date'].min()\n",
    "\n",
    "    ce_strikes = data[(data['instrument_type'] == 'CE') & \n",
    "                      (data['instrument_name'] == instrument) & \n",
    "                      (data['expiry_date'] == nearest_expiry) & \n",
    "                      (data['datetime'] == entry_datetime)].copy()\n",
    "\n",
    "    ce_strikes = ce_strikes.sort_values(by='close',ascending=False)\n",
    "    ce_strike_price = ce_strikes[ce_strikes['close'] == ce_strikes[ce_strikes['close'] >= option_value]['close'].min()]['strike_price'].iloc[0]\n",
    "\n",
    "    try:\n",
    "        ce_data = data[(data['instrument_type'] == 'CE') & \n",
    "                       (data['instrument_name'] == instrument) & \n",
    "                       (data['expiry_date'] == nearest_expiry) & \n",
    "                       (data['strike_price'] == ce_strike_price)].copy()\n",
    "        ce_symbol = ce_data['ticker'].iloc[0]\n",
    "    except:\n",
    "        while ce_strike_alternatives < 5:\n",
    "            try:\n",
    "                ce_data = data[(data['instrument_type'] == 'CE') & \n",
    "                               (data['instrument_name'] == instrument) & \n",
    "                               (data['expiry_date'] == nearest_expiry) & \n",
    "                               (data['strike_price'] == ce_strike_price+base)].copy()\n",
    "                ce_symbol = ce_data['ticker'].iloc[0]\n",
    "                ce_strike_alternatives+=1\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    #if ce data is retrieved reset the index\n",
    "    ce_data.reset_index(drop=True,inplace=True)\n",
    "    ce_data.sort_values(by='datetime',inplace=True)\n",
    "\n",
    "    pe_strikes = data[(data['instrument_type'] == 'PE') & \n",
    "                        (data['instrument_name'] == instrument) & \n",
    "                        (data['expiry_date'] == nearest_expiry) & \n",
    "                        (data['datetime'] == entry_datetime)].copy()\n",
    "\n",
    "    pe_strikes = pe_strikes.sort_values(by='open',ascending=False)\n",
    "    pe_strike_price = pe_strikes[pe_strikes['close'] == pe_strikes[pe_strikes['close'] >= option_value]['close'].min()]['strike_price'].iloc[0]\n",
    "\n",
    "    #get the pe data if some error comes, then shift the pe strike to atm-1\n",
    "    #then also if the error comes, skip the day\n",
    "    try:\n",
    "        pe_data = data[(data['instrument_type'] == 'PE') & \n",
    "                        (data['instrument_name'] == instrument) & \n",
    "                        (data['expiry_date'] == nearest_expiry) & \n",
    "                        (data['strike_price'] == pe_strike_price)].copy()\n",
    "        pe_symbol = pe_data['ticker'].iloc[0]\n",
    "    except:\n",
    "        while pe_strike_alternatives < 5:\n",
    "            try:\n",
    "                pe_data = data[(data['instrument_type'] == 'PE') & \n",
    "                               (data['instrument_name'] == instrument) & \n",
    "                               (data['expiry_date'] == nearest_expiry) & \n",
    "                               (data['strike_price'] == pe_strike_price+base)].copy()\n",
    "                pe_symbol = pe_data['ticker'].iloc[0]\n",
    "                pe_strike_alternatives+=1\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    #if pe data is retrieved reset the index\n",
    "    pe_data.reset_index(drop=True,inplace=True)\n",
    "    pe_data.sort_values(by='datetime',inplace=True)\n",
    "\n",
    "    #rearrange the futures data\n",
    "    futures_data = futures_data[['datetime','open','high','low','close']]\n",
    "    futures_data.set_index('datetime',inplace=True)\n",
    "\n",
    "    #rearrange the ce data\n",
    "    ce_data = ce_data[['datetime','open','high','low','close']]\n",
    "    ce_data = ce_data.rename(columns={'open':'ce_open',\n",
    "                                        'high':'ce_high',\n",
    "                                        'low':'ce_low',\n",
    "                                        'close':'ce_close'})\n",
    "    ce_data.drop_duplicates(subset='datetime',keep='first',inplace=True)\n",
    "    ce_data.set_index('datetime',inplace=True)\n",
    "\n",
    "    #rearrange the pe data\n",
    "    pe_data = pe_data[['datetime','open','high','low','close']]\n",
    "    pe_data = pe_data.rename(columns={'open':'pe_open',\n",
    "                                        'high':'pe_high',\n",
    "                                        'low':'pe_low',\n",
    "                                        'close':'pe_close'})\n",
    "    pe_data.drop_duplicates(subset='datetime',keep='first',inplace=True)\n",
    "    pe_data.set_index('datetime',inplace=True)\n",
    "\n",
    "    #combine the futures, ce and pe\n",
    "    intraday_data = pd.concat([futures_data,ce_data,pe_data],axis=1)\n",
    "    intraday_data.reset_index(inplace=True)\n",
    "    intraday_data = intraday_data.ffill()\n",
    "\n",
    "    #set the traded prices for futures, ce and pe\n",
    "    traded_prices = intraday_data[intraday_data['datetime'] == entry_datetime].iloc[0]\n",
    "    futures_entry_price = traded_prices[entry_offset]\n",
    "    ce_entry_price = traded_prices[f'ce_{entry_offset}']\n",
    "    pe_entry_price = traded_prices[f'pe_{entry_offset}']\n",
    "\n",
    "    #if any of the traded prices comes as nan\n",
    "    #try shifting the time to next minute until none of them come as nan\n",
    "    #try for only 5 times\n",
    "    while entry_minutes_alternative <= 5:\n",
    "\n",
    "        if (np.isnan(futures_entry_price) == True)|(np.isnan(ce_entry_price) == True)|(np.isnan(pe_entry_price) == True):\n",
    "\n",
    "            entry_datetime = entry_datetime + datetime.timedelta(minutes=entry_minutes_alternative)\n",
    "            traded_prices = intraday_data[intraday_data['datetime'] == entry_datetime].iloc[0]\n",
    "            futures_entry_price = traded_prices[entry_offset]\n",
    "            ce_entry_price = traded_prices[f'ce_{entry_offset}']\n",
    "            pe_entry_price = traded_prices[f'pe_{entry_offset}']\n",
    "            entry_minutes_alternative+=1\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #compute the ce and pe stop_loss\n",
    "    ce_stop_loss = ce_entry_price + ce_entry_price*stop_loss_percentage\n",
    "    pe_stop_loss = pe_entry_price + pe_entry_price*stop_loss_percentage\n",
    "    \n",
    "    try:\n",
    "        #filter only the required data\n",
    "        entry_time_index = intraday_data[intraday_data['datetime'] == entry_datetime].index[0]\n",
    "        exit_time_index = intraday_data[intraday_data['datetime'] == exit_datetime].index[0]\n",
    "        intraday_data = intraday_data[entry_time_index:exit_time_index+1]\n",
    "    except IndexError:\n",
    "        print(f'ERROR ON DATE {data_date}')\n",
    "        continue\n",
    "    \n",
    "    ce_stop_loss_counter = 0\n",
    "    pe_stop_loss_counter = 0\n",
    "    ce_exit_datetime = ''\n",
    "    pe_exit_datetime = ''\n",
    "    ce_exit_price = 0\n",
    "    pe_exit_price = 0\n",
    "    ce_pnl = 0\n",
    "    pe_pnl = 0\n",
    "    pnl = 0\n",
    "\n",
    "    intraday_data['ce_pnl'] = ce_entry_price - intraday_data['ce_close']\n",
    "    intraday_data['pe_pnl'] = pe_entry_price - intraday_data['pe_close']\n",
    "    intraday_data['pnl'] = intraday_data['ce_pnl'] + intraday_data['pe_pnl']\n",
    "\n",
    "    intraday_data['ce_stop_loss_triggered'] = np.where(intraday_data[f'ce_{stop_loss_offset}'] >= ce_stop_loss,1,np.NaN)\n",
    "    intraday_data['ce_stop_loss_triggered'].ffill(inplace=True)\n",
    "\n",
    "    intraday_data['pe_stop_loss_triggered'] = np.where(intraday_data[f'pe_{stop_loss_offset}'] >= pe_stop_loss,1,np.NaN)\n",
    "    intraday_data['pe_stop_loss_triggered'].ffill(inplace=True)\n",
    "\n",
    "    try:\n",
    "        ce_exit_data = intraday_data[intraday_data['ce_stop_loss_triggered'] == 1].iloc[0]\n",
    "        ce_exit_price = round(ce_stop_loss/0.05)*0.05\n",
    "        ce_stop_loss_counter = 1\n",
    "    except:\n",
    "        ce_exit_data = intraday_data.iloc[-1]\n",
    "        ce_exit_price = ce_exit_data['ce_close']\n",
    "\n",
    "    try:\n",
    "        pe_exit_data = intraday_data[intraday_data['pe_stop_loss_triggered'] == 1].iloc[0]\n",
    "        pe_exit_price = round(pe_stop_loss/0.05)*0.05\n",
    "        pe_stop_loss_counter = 1\n",
    "    except:\n",
    "        pe_exit_data = intraday_data.iloc[-1]\n",
    "        pe_exit_price = pe_exit_data['pe_close']\n",
    "\n",
    "    ce_exit_datetime = ce_exit_data['datetime']\n",
    "    pe_exit_datetime = pe_exit_data['datetime']\n",
    "\n",
    "    ce_exit_time = ce_exit_datetime.time()\n",
    "    pe_exit_time = pe_exit_datetime.time()\n",
    "\n",
    "    trade_log = trade_log.append({'entry_date':data_date,\n",
    "                                  'days_to_expiry':(nearest_expiry - data_date).days,\n",
    "                                  'stop_loss':stop_loss_percentage*100,\n",
    "                                  'ce_entry_time':entry_time,\n",
    "                                  'ce_symbol':ce_symbol,\n",
    "                                  'ce_entry':ce_entry_price,\n",
    "                                  'ce_exit':ce_exit_price,\n",
    "                                  'ce_exit_time':ce_exit_time,\n",
    "                                  'ce_pnl':ce_entry_price-ce_exit_price,\n",
    "                                  'pe_entry_time':entry_time,\n",
    "                                  'pe_symbol':pe_symbol,\n",
    "                                  'pe_entry':pe_entry_price,\n",
    "                                  'pe_exit':pe_exit_price,\n",
    "                                  'pe_exit_time':pe_exit_time,\n",
    "                                  'pe_pnl':pe_entry_price-pe_exit_price},ignore_index=True)\n",
    "\n",
    "    trade_log['pnl'] = trade_log['ce_pnl']+trade_log['pe_pnl']\n",
    "    trade_log['weekday'] = trade_log['entry_date'].apply(lambda x: weekday_dict[x.weekday()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4d04ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_log['entry_price'] = trade_log['ce_entry'] + trade_log['pe_entry']\n",
    "trade_log['exit_price'] = trade_log['ce_exit'] + trade_log['pe_exit']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
